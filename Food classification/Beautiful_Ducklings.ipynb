{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Food 101\n",
    "\n",
    "This is a Jupyter Notebook containing context and calculations for our Machine Learning end-of-year project.\n",
    "\n",
    "*Main goal:* We want to train a machine learning model that - given an image of a plate of food - is able to tell us what kind of dish it is.\n",
    "\n",
    "*Strategies:*\n",
    "*   kNN algorithm (with different parameters)\n",
    "*   `DecisionTreeClassifier` from sklearn\n",
    "*   XGBoost?"
   ],
   "metadata": {
    "id": "pQUfO6qKwDWm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "This [Food 101](https://www.kaggle.com/datasets/dansbecker/food-101) or [Food images - Food 101](https://www.kaggle.com/datasets/kmader/food41?select=images)  dataset from Kaggle contains nearly 10000 images of dishes divided into 101 types of food."
   ],
   "metadata": {
    "id": "yWNU8cDHyFmv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tf as tf\n",
    "!pip install -q gdown httpimport\n",
    "!pip install kaggle"
   ],
   "metadata": {
    "id": "UZNydlcl0m19",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e366afa-6fd3-44d6-d8db-550fb904e8a2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir ~/.kaggle"
   ],
   "metadata": {
    "id": "wSloDrskQwqn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add kaggle.json file from your kaggle profile to ~/.kaggle/\n"
   ],
   "metadata": {
    "id": "MWiDJ9LLQ9kR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Downloading data\n",
    "!kaggle datasets download 'dansbecker/food-101' -p /path/data"
   ],
   "metadata": {
    "id": "NdWWb0t1Q5jo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "90965c57-bc15-4082-90af-eb8b00b1eb63"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
      "    from kaggle.cli import main\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
      "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
      "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Unzipping data from Kaggle\n",
    "!unzip /path/data/food-101.zip -d data/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0_48LlK3Qxn",
    "outputId": "eed82d3f-12bf-4c98-edbc-2f60782ce85c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unzip:  cannot find or open /path/data/food-101.zip, /path/data/food-101.zip.zip or /path/data/food-101.zip.ZIP.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "fErUY6Jd0KbW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## kNN algorithm\n"
   ],
   "metadata": {
    "id": "LUChY5HWD5Jf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Complete Python script for kNN\n",
    "\n",
    "**NOTE:** Since the model requires a lot of computing power it should probably not be run in Google Colab. Adjusting the following parameters will have an effect on execution time:"
   ],
   "metadata": {
    "id": "91TUR3vdYGXL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "how_many_classes = 10  # out of 101\n",
    "picture_size = 48      # the image will be resized to a square of this size by OpenCV"
   ],
   "metadata": {
    "id": "ykfwMqUKa0on"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    # Data loading\n",
    "    pictures = '/food-101/images'\n",
    "\n",
    "    # Selects x first categories/food classes\n",
    "    classes = [x[:-1:] for x in open('food-101/meta/classes.txt', 'r').readlines()][:how_many_classes:]\n",
    "    labels = [x[:-1:] for x in open('food-101/meta/labels.txt', 'r').readlines()][:how_many_classes:]\n",
    "    # Conversion from string to id\n",
    "    conversion = dict()\n",
    "    for index in range(how_many_classes):\n",
    "        conversion[classes[index]] = index\n",
    "\n",
    "    test_path = [x[:-1:] for x in open('food-101/meta/test.txt', 'r').readlines()]\n",
    "    train_path = [x[:-1:] for x in open('food-101/meta/train.txt', 'r').readlines()]\n",
    "\n",
    "    test_x = []\n",
    "    train_x = []\n",
    "    test_y = []\n",
    "    train_y = []\n",
    "\n",
    "    # Creating test_x and test_y based on chosen classes\n",
    "    for path in test_path:\n",
    "        path_class = path.split('/')[0]\n",
    "        if path_class in classes:\n",
    "            img = cv.imread(f'food-101/images/{path}.jpg')\n",
    "            if img.shape != (picture_size, picture_size, 3):\n",
    "                img = cv.resize(img, (picture_size, picture_size))\n",
    "            test_x.append(img)\n",
    "            test_y.append(conversion[path_class])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Creating train_x and train_y based on chosen classes\n",
    "    for path in train_path:\n",
    "        path_class = path.split('/')[0]\n",
    "        if path_class in classes:\n",
    "            img = cv.imread(f'food-101/images/{path}.jpg')\n",
    "            if img.shape != (picture_size, picture_size, 3):\n",
    "                img = cv.resize(img, (picture_size, picture_size))\n",
    "            train_x.append(img)\n",
    "            train_y.append(conversion[path_class])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # cv.imshow('Picture', test_x[0])\n",
    "    # cv.imshow('Resized', cv.resize(test_x[0], (50, 50)))\n",
    "    # cv.waitKey(3000)\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    # Prepare data for knn algorithm\n",
    "    knn_train_y = np.eye(how_many_classes)[train_y]\n",
    "    knn_test_y = np.eye(how_many_classes)[test_y]\n",
    "    train_x = np.array([picture.flatten() for picture in train_x])\n",
    "    test_x = np.array([picture.flatten() for picture in test_x])\n",
    "\n",
    "    train_x = (train_x - train_x.min(0)) / train_x.ptp(0)\n",
    "    test_x = (test_x - test_x.min(0)) / test_x.ptp(0)\n",
    "\n",
    "    print('Separated into subsets')\n",
    "\n",
    "    # Knn alg\n",
    "    features = len(test_x[0])\n",
    "    k = 5\n",
    "    x_new_train = tf.compat.v1.placeholder(shape=[None, features], dtype=tf.float32)\n",
    "    y_new_train = tf.compat.v1.placeholder(shape=[None, len(knn_test_y[0])], dtype=tf.float32)\n",
    "    x_new_test = tf.compat.v1.placeholder(shape=[None, features], dtype=tf.float32)\n",
    "\n",
    "    manht_distance = tf.reduce_sum(tf.abs(tf.subtract(x_new_train, tf.expand_dims(x_new_test, 1))), axis=2)\n",
    "\n",
    "    print('Distance done!')\n",
    "\n",
    "    _, top_k_indices = tf.nn.top_k(tf.negative(manht_distance), k=k)\n",
    "    top_k_labels = tf.gather(y_new_train, top_k_indices)\n",
    "\n",
    "    predictions_sumup = tf.reduce_sum(top_k_labels, axis=1)\n",
    "    make_prediction = tf.argmax(predictions_sumup, axis=1)\n",
    "\n",
    "    sess = tf.compat.v1.Session()\n",
    "    # outcome_prediction = sess.run(make_prediction, feed_dict={x_new_train: train_x, x_new_test: test_x,\n",
    "    #                                                           y_new_train: knn_train_y})\n",
    "\n",
    "    accuracy = 0\n",
    "    batch_size = 2\n",
    "\n",
    "    for i in range(len(knn_test_y) // batch_size):\n",
    "        res = sess.run(make_prediction,\n",
    "                       feed_dict={x_new_train: train_x, x_new_test: test_x[i * batch_size:(i + 1) * batch_size],\n",
    "                                  y_new_train: knn_train_y})\n",
    "        for pred, actual in zip(res, knn_test_y[i * batch_size:(i + 1) * batch_size]):\n",
    "            if pred == np.argmax(actual):\n",
    "                accuracy += 1\n",
    "\n",
    "    print(\"Accuracy rate:\", accuracy / len(knn_test_y))"
   ],
   "metadata": {
    "id": "9XptwwKaYDny"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "id": "li_HobF0D_vN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to create a classifier similar to [this one](https://github.com/pooji0401/Image-Classification-System-using-Decision-Trees/blob/master/Image%20Classification%20System.ipynb) - ..."
   ],
   "metadata": {
    "id": "O6ioHHktJPu1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Additional imports\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "id": "hQUga4csYkt7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Complete Python script for decision trees\n",
    "\n",
    "**NOTE:** Since the model requires a lot of computing power it should probably not be run in Google Colab (and depending on the program parameters it may still take a few hours)."
   ],
   "metadata": {
    "id": "yuplR7n4Yqo1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "how_many_classes = 10  # out of 101\n",
    "picture_size = 48      # the image will be resized to a square of this size by OpenCV"
   ],
   "metadata": {
    "id": "2z6pbDxrbXoO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Data loading\n",
    "pictures = '/food-101/images'\n",
    "\n",
    "# Selects x first categories/food classes\n",
    "classes = [x[:-1:] for x in open('food-101/meta/classes.txt', 'r').readlines()][:how_many_classes:]\n",
    "labels = [x[:-1:] for x in open('food-101/meta/labels.txt', 'r').readlines()][:how_many_classes:]\n",
    "\n",
    "# Conversion from string to id\n",
    "conversion = dict()\n",
    "for index in range(how_many_classes):\n",
    "    conversion[classes[index]] = index\n",
    "\n",
    "test_path = [x[:-1:] for x in open('food-101/meta/test.txt', 'r').readlines()]\n",
    "train_path = [x[:-1:] for x in open('food-101/meta/train.txt', 'r').readlines()]\n",
    "\n",
    "test_x = []\n",
    "train_x = []\n",
    "test_y = []\n",
    "train_y = []\n",
    "\n",
    "# Creating test_x and test_y based on chosen classes\n",
    "for path in test_path:\n",
    "    path_class = path.split('/')[0]\n",
    "    if path_class in classes:\n",
    "        img = cv.imread(f'food-101/images/{path}.jpg')\n",
    "        if img.shape != (picture_size, picture_size, 3):\n",
    "            img = cv.resize(img, (picture_size, picture_size))\n",
    "        test_x.append(img)\n",
    "        test_y.append(conversion[path_class])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Creating train_x and train_y based on chosen classes\n",
    "for path in train_path:\n",
    "    path_class = path.split('/')[0]\n",
    "    if path_class in classes:\n",
    "        img = cv.imread(f'food-101/images/{path}.jpg')\n",
    "        if img.shape != (picture_size, picture_size, 3):\n",
    "            img = cv.resize(img, (picture_size, picture_size))\n",
    "        train_x.append(img)\n",
    "        train_y.append(conversion[path_class])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "D_train = [_.flatten() for _ in train_x]\n",
    "D_test = [_.flatten() for _ in test_x]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(D_train, train_y)\n",
    "\n",
    "D_train = np.array(D_train)\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "print(n_nodes)\n",
    "print(clf.tree_.max_depth)\n",
    "\n",
    "pred = clf.predict(D_test)\n",
    "\n",
    "print('Accuracy rate:', accuracy_score(pred, test_y))\n"
   ],
   "metadata": {
    "id": "g5BNiCvQEBqi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fg9RZ8BBV4-T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes"
   ],
   "metadata": {
    "id": "MPn0dAm3s87P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Ideas*:\n",
    "*   keep the current way of calculating the distance, but only take every 10th or so pixel into account (since things close to one another tend to be similar)\n",
    "*   introduce noise to the data (greying some random pixels)\n",
    "*   consider only the inner 90% of the frame (in order to analyze the food itself rather than the place setting)\n",
    "\n"
   ],
   "metadata": {
    "id": "NT7a015XtG9Y"
   }
  }
 ]
}
